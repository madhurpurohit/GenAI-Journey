# ðŸŽ¬ Optimized GraphRAG Indexing Pipeline â€” Complete Flow Documentation

## Overview

This is the **optimized version** of the GraphRAG Indexing Pipeline originally built in Day18. The core objective remains the same â€” read a PDF file containing 1000 movies, extract structured data, and store it in two databases:

1. **Neo4j** (Graph Database) â€” Stores facts and relationships (e.g., "Which actor acted in which movie")
2. **Pinecone** (Vector Database) â€” Stores embeddings for similarity-based search (e.g., "Show me movies like this")

The pipeline still runs in 3 steps, but **Step 3 (Vector Store)** has been fundamentally redesigned:

| Step   | Day18 (Previous)                         | Day19 (Optimized)                                   |
| ------ | ---------------------------------------- | --------------------------------------------------- |
| Step 1 | PDF â†’ Gemini â†’ Extract entities          | Same (no change)                                    |
| Step 2 | Entities â†’ Neo4j graph                   | Same (no change)                                    |
| Step 3 | Entities â†’ Clean text â†’ Embed â†’ Pinecone | **PDF â†’ Parse â†’ Chunk raw text â†’ Embed â†’ Pinecone** |

### Why Was Step 3 Redesigned?

In Day18, the vector store was built from **entity-based clean text** â€” each movie's entities (title, director, actors, genres, themes, awards) were combined into a single sentence and embedded. This approach had a critical limitation:

- **Information loss** â€” The clean text was a **lossy summary** of the movie data. Any information in the PDF that was not captured as a structured entity (e.g., plot descriptions, production notes, interesting trivia) was permanently lost from the vector store
- **Dependency on entity extraction** â€” If entity extraction missed a movie or extracted incomplete data, the vector store would also be incomplete
- **Shallow embeddings** â€” The generated sentences were formulaic ("X is a Y movie released in Z"), producing embeddings that captured **structure** rather than **meaning**

In Day19, the vector store is built from **raw PDF text chunks** â€” the PDF is parsed independently, the text is split into natural chunks, and each chunk is embedded directly. This means:

- **No information loss** â€” Every word from the PDF is preserved in the vector store
- **Independence** â€” The vector store does not depend on entity extraction; even if Step 1 fails, Step 3 can still work
- **Richer embeddings** â€” Raw text captures the full semantic meaning, not just structured fields

---

## Entry Point: `7_runIndexing.js`

This is the **starting point** of the entire indexing pipeline â€” running this file kicks off the whole process.

### PDF Path Requirement

First, a `pdfPath` variable is defined which holds the path to the PDF file (`./data/movies.pdf`). This path is passed to the `runIndexing` function. If the PDF path is not available, the program prints an error message and exits.

### `runIndexing(pdfPath)` â€” Main Orchestrator Function

This is an **async function** that controls the entire pipeline. It acts as a manager â€” calling specialist functions in the correct order without doing any heavy lifting itself.

This function performs 3 tasks sequentially:

#### Step 1 â†’ `extractAllEntities(pdfPath)` is called

- This function comes from the `4_entityExtractor.js` file
- It receives the PDF file path as input
- It uploads the PDF to Gemini AI and extracts structured JSON data â€” each movie's title, director, actors, genres, themes, awards
- The result is an **array of entities**

#### Step 2 â†’ `buildGraph(entities)` is called

- This function comes from the `5_graphBuilder.js` file
- It receives the entities array from Step 1
- It stores each entity as nodes and relationships in the Neo4j database

#### Step 3 â†’ `buildVectorStore(pdfPath)` is called

> **ðŸ”„ Key Change from Day18:** In the previous version, `buildVectorStore(entities)` received the **entities array** from Step 1. In the optimized version, `buildVectorStore(pdfPath)` receives the **PDF file path** directly. This is because the vector store no longer depends on extracted entities â€” it processes the PDF independently from scratch (parse â†’ chunk â†’ embed). This makes Step 3 completely decoupled from Step 1.

- This function comes from the `6_vectorStore.js` file
- It receives the PDF path directly (not entities)
- It parses the PDF locally, splits the text into chunks, generates embeddings for each chunk, and stores them in Pinecone

#### Error Handling & Cleanup

If an error occurs at any step, the `catch` block logs that error. Whether the pipeline succeeds or fails, the `finally` block calls `closeConnections()` (imported from `2_config.js`) â€” this closes the Neo4j connection pool to free up resources.

---

## Foundation: `2_config.js` â€” All Connections in One Place

This file is the **backbone** of the entire project. All other files import their database connections and AI models from here. If any API key or connection detail needs to change, it only needs to be modified in this single file.

> **No changes from Day18** â€” This file remains identical in its purpose and functionality.

### This file sets up 4 things:

1. **Neo4j Driver** â€” Used to connect to the graph database. It creates a connection pool (meaning it can handle multiple queries simultaneously). The `neo4j+s://` protocol is used, which is the Bolt protocol with TLS encryption (required for cloud-based Aura).

2. **Pinecone Client & Index** â€” Used to connect to the vector database. `Pinecone()` creates the client, then `pinecone.index()` points to a specific index (similar to a table). The index name comes from the `.env` file.

3. **Gemini LLM (via LangChain)** â€” This is Google's AI model that understands text and produces structured output. The `gemini-2.5-flash` model is used because it is fast and cost-effective. `temperature: 0` is set to make the output deterministic (same input always produces the same output).

4. **Google GenAI SDK** â€” This is Google's direct SDK. It is used in two places: for generating embeddings and for uploading PDF files. The direct SDK is used instead of LangChain because it is simpler and is already required for PDF uploads.

### Embedding Functions

- **`embedText(text)`** â€” Generates an embedding for a single text. It uses the `gemini-embedding-001` model and returns a 3072-dimensional vector. The response contains an `.embeddings` array (even for a single text), and each element has a `.values` property which is the actual vector.

- **`embedTexts(texts)`** â€” Generates embeddings for multiple texts at once. It uses the same model and returns an array of vectors.

### `closeConnections()`

This function closes the Neo4j driver's connection pool. It is called when all pipeline work is complete, from the `finally` block in `7_runIndexing.js`.

---

## Step 1 Detail: `4_entityExtractor.js` â€” Entity Extraction from PDF

This file's job is to send the PDF to Gemini AI and receive structured JSON entities back.

> **ðŸ”„ Key Change from Day18:** The model used for extraction has been upgraded from `gemini-2.5-flash-lite` to `gemini-2.5-flash`. The "lite" version was lighter and cheaper but produced lower quality output â€” it was more likely to return malformed JSON, miss entities, or hallucinate data. The upgrade to the full `gemini-2.5-flash` model provides better accuracy and more reliable JSON output, which is critical when extracting structured data for a knowledge graph where precision matters.

### Approach â€” What is the strategy?

Instead of locally parsing the PDF and extracting text, this file uploads the PDF directly to the **Gemini Files API**. Gemini's 1 million token context window is large enough to read the entire 1000-movie PDF at once. It then extracts entities in batches (50 movies per batch).

**Efficiency**: 1000 movies Ã· 50 per batch = only 20 API calls (not a separate call for each movie â€” it is done in bulk).

### Extraction Prompt

A fixed `EXTRACTION_PROMPT` string is defined that tells Gemini what to do:

- Extract movies {START} through {END} from the PDF
- Return a JSON structure for each movie containing the movie title, year, director name, actors list, genres list, themes list, and awards list
- If awards say "None", return an empty array
- The response should contain only valid JSON â€” no markdown or explanations

`{START}` and `{END}` are placeholders that get replaced for each batch.

### `uploadPDF(pdfPath)` â€” Uploading the PDF to Gemini's Servers

This function uploads the PDF file to Google's servers via `genai.files.upload()`. After uploading, the file is not immediately ready â€” its state is "PROCESSING". The function runs a polling loop: every 3 seconds it checks whether the file has finished processing. When the state changes from "PROCESSING":

- If the state is "FAILED", an error is thrown
- Otherwise, a `fileInfo` object is returned containing the file's `uri`, `name`, and `mimeType`

The uploaded file remains on Google's servers for **48 hours**, after which it is automatically deleted.

### `extractBatch(fileInfo, start, end, attempt)` â€” Extracting a Single Batch

This function extracts a specific range of movies (e.g., 1 to 50, 51 to 100). It receives the uploaded file's `fileInfo` object.

**How the API call works:**

The `genai.models.generateContent()` function is called with:

- A specified model (`gemini-2.5-flash`)
- A `contents` array containing two parts:
  1. **PDF file reference** â€” Here, the **`createPartFromUri(fileInfo.uri, fileInfo.mimeType)`** function is used
  2. **Text prompt** â€” Which specifies which movies to extract

#### `createPartFromUri()` Explained

This function is imported from the `@google/genai` package. Its job is to create a **"part" object** that tells the Gemini API that there is a file already uploaded on Google's servers, and to include it in the context.

**Why is it necessary?** â€” When you send multi-modal content (text + file) to the Gemini API, you need to provide "parts" inside the `contents` array. For text, you simply provide `{ text: "..." }`. However, for an uploaded file, you need to specify its URI and MIME type â€” this is exactly what `createPartFromUri()` does. It returns an object that Gemini can understand, essentially saying "this file is stored on my servers at this URI, go read it from there".

**When is it used?** â€” Every time a batch needs to be extracted. The PDF is uploaded only once, but each batch API call uses `createPartFromUri()` to create a new reference so that Gemini knows which file to read. It does **not re-upload** the file â€” it simply provides a pointer to the already uploaded file.

**Response processing:**

The raw text returned by Gemini sometimes contains markdown backticks. These are first cleaned out, and then `JSON.parse()` is used to parse the result. If the result is not an array, it is wrapped in one before being returned.

#### Retry Strategy

Each batch gets a maximum of 3 attempts:

- **429 Error (Rate Limit)** â€” This means Google's servers have indicated too many requests are being sent. In this case, a longer wait is applied: 30s, 60s, 90s (attempt Ã— 30 seconds)
- **Any other error** (JSON parse failure, network timeout, 500/503 server error) â€” A shorter wait is applied: 10s, 20s, 30s (attempt Ã— 10 seconds)
- If all 3 attempts fail, an empty array is returned and that batch is marked as "failed"

### `extractAllEntities(pdfPath, totalMovies, batchSize)` â€” The Complete Extraction Process

This is the main function that orchestrates the entire extraction. Default values are: 1000 movies, 50 per batch.

**Step-by-step breakdown:**

1. **PDF upload** â€” `uploadPDF(pdfPath)` is called. The file is uploaded once and a `fileInfo` object is obtained

2. **Building the batch list** â€” A loop calculates which ranges need to be extracted: (1-50), (51-100), (101-150), ... (951-1000). This results in a total of 20 batches

3. **Pass 1 â€” Parallel extraction** â€” 5 batches are run simultaneously (in parallel). This is controlled by `CONCURRENCY = 5`. This means 20 batches Ã· 5 parallel = 4 rounds. In each round, `Promise.all()` is used to fire 5 requests at the same time. A small 2-second break is added between rounds. Successfully returned batches have their results added to the main list. Failed batches are added to the `failedBatches` list.

4. **Pass 2 â€” Retrying failed batches** â€” If any batches failed, after a 5-second wait, all failed batches are retried one by one (sequentially), with a 2-second gap between each retry

5. **Cleanup** â€” The uploaded PDF file is deleted from Google's servers using `genai.files.delete()` (it would auto-delete in 48 hours anyway, but proactive cleanup is better practice)

6. **Return** â€” The final result is an array containing all extracted entities. If some movies are missing, a warning is printed

---

## Step 2 Detail: `5_graphBuilder.js` â€” Building the Graph in Neo4j

> **No changes from Day18** â€” This file is completely identical to the Day18 version.

This file's job is to store the extracted entities as nodes and relationships in a graph database (Neo4j).

### Core Concept â€” MERGE vs CREATE

When inserting data into the graph, there is an important decision:

- **CREATE** â€” Always creates a new node, even if the same data already exists. This causes duplicates (e.g., two "Zendaya" nodes)
- **MERGE** â€” First checks whether the node already exists. If yes, it uses the existing one; if no, it creates a new one. This prevents duplicates

The entire project uses **MERGE** to ensure that each actor or genre exists as only a single node.

### `buildGraph(entities)` â€” Main Function

This function controls the entire graph building process. It receives the entities array (which comes from Step 1).

**Step 1 â€” Creating indexes:**

Before inserting any data, indexes are created in Neo4j for each label (Movie, Director, Actor, Genre, Theme, Award). Why are indexes necessary? Because when performing a MERGE, Neo4j first needs to check "does this node already exist?". Without an index, this check requires **scanning all nodes** (slow). With an index, it uses a lookup table for instant retrieval (fast). `CREATE INDEX IF NOT EXISTS` is used so that if the index already exists, no error is thrown.

**Step 2 â€” Inserting movies:**

A loop calls `insertMovieGraph(entity)` for each entity. After every 50 movies or at the last movie, progress is logged.

**Step 3 â€” Printing statistics:**

After all data is inserted, two Cypher queries are executed:

- Count total nodes (`MATCH (n) RETURN count(n)`)
- Count total relationships (`MATCH ()-[r]->() RETURN count(r)`)

### `insertMovieGraph(entity)` â€” Inserting a Complete Graph for a Single Movie

This function creates all nodes and relationships in Neo4j for a single movie entity. It runs within **a single transaction** (`session.executeWrite`) â€” meaning either all data is inserted or none of it is (all-or-nothing).

Inside the transaction, the following nodes and relationships are created:

1. **Movie node** â€” A Movie node is MERGEd based on the title, and the year is set
2. **Director node + DIRECTED relationship** â€” A Director node is MERGEd, then a `DIRECTED` relationship is MERGEd between that Director and the Movie
3. **Actor nodes + ACTED_IN relationships** â€” For each actor, an Actor node is MERGEd and an `ACTED_IN` relationship connects it to the Movie
4. **Genre nodes + BELONGS_TO relationships** â€” For each genre, a Genre node is MERGEd and a `BELONGS_TO` relationship connects the Movie to the Genre
5. **Theme nodes + EXPLORES relationships** â€” For each theme, a Theme node is MERGEd and an `EXPLORES` relationship connects the Movie to the Theme
6. **Award nodes + WON relationships** â€” For each award, regex pattern matching is applied to parse the award type and category

#### Award Regex Parsing

Awards in the PDF appear in the following format: `"Oscar (Best Cinematography)"`. A regex pattern `/^(.+?)\s*\((.+)\)$/` is used to extract:

- `match[1]` = `"Oscar"` (award type)
- `match[2]` = `"Best Cinematography"` (category)

These are stored as separate properties in the Award node (`name` = award type, `category` = category). A `WON` relationship is then created between the Movie and the Award. If the award format does not match, it is skipped.

After usage, the session is closed via `session.close()` (in the `finally` block) â€” this is essential because each session in Neo4j consumes a database connection.

---

## Step 3 Detail: `6_vectorStore.js` â€” Chunk-Based Vector Embedding (Completely Redesigned)

> **ðŸ”„ Major Rewrite from Day18** â€” This is the most significantly changed file in the entire pipeline. The entire approach to building the vector store has been redesigned.

### What Changed and Why

| Aspect                 | Day18 (Previous)                                    | Day19 (Optimized)                                            | Why                                                      |
| ---------------------- | --------------------------------------------------- | ------------------------------------------------------------ | -------------------------------------------------------- |
| **Input**              | Entities array (from Step 1)                        | PDF file path (independent)                                  | Decouples vector store from entity extraction            |
| **Text source**        | AI-generated clean sentence per movie               | Raw PDF text, split into natural chunks                      | Preserves all original information                       |
| **Embedding function** | `embedTexts()` (batch)                              | `embedText()` (single, with retry)                           | Per-chunk retry ensures no silent failures               |
| **Record ID**          | Movie title (e.g., `"the-dark-knight"`)             | Sequential chunk ID (e.g., `"chunk-0"`)                      | Chunks are text blocks, not movies                       |
| **Metadata**           | Title, year, director, genres, themes, actors, text | Only the raw text of the chunk                               | Raw text is self-contained â€” no structured fields needed |
| **Retry logic**        | None (relied on `embedTexts` to succeed)            | Dedicated `embedWithRetry()` with 3 attempts                 | More robust against transient failures                   |
| **Import**             | `embedTexts`, `pineconeIndex` from config           | `embedText`, `pineconeIndex` from config + `fs`, `pdf-parse` | Needs filesystem access for PDF parsing                  |

### Why Move from Entity-Based to Chunk-Based?

In Day18, the vector store was built by taking each movie's extracted entities (title, genres, director, etc.) and crafting a clean sentence like "The Dark Knight is a Action, Crime movie released in 2008. Directed by Christopher Nolan. Starring Christian Bale, Heath Ledger." This was then embedded and stored.

**The problem:** This sentence is a **lossy compression** of the movie data. If the PDF contains rich descriptions, plot summaries, or additional notes about a movie, none of that makes it into the vector store. The embeddings only capture the structured fields â€” not the full semantic richness.

**The solution:** Instead of depending on entities, the optimized version reads the PDF directly, splits it into chunks, and embeds the raw text. This way, **every piece of information** from the PDF is captured in the vector store, making similarity searches significantly more accurate and informative.

### New Imports

This file now imports:

- **`fs`** â€” Node.js file system module for reading the PDF from disk
- **`pdf-parse`** (specifically `pdf-parse/lib/pdf-parse.js`) â€” Library for extracting text from PDF files
- **`embedText`** â€” Single-text embedding function from `2_config.js` (previously used `embedTexts` for batch embedding)
- **`pineconeIndex`** â€” Pinecone index client from `2_config.js`

### Constants

Three constants are defined at the top:

- **`EMBED_CONCURRENCY = 5`** â€” How many embeddings to generate in parallel at a time
- **`EMBED_DELAY_MS = 500`** â€” Delay in milliseconds between embedding rounds to avoid overwhelming the API
- **`UPSERT_BATCH_SIZE = 100`** â€” How many vectors to send to Pinecone in a single upsert call

> **Why constants at the top?** â€” In Day18, these values were hardcoded inside functions (e.g., `batchSize = 50`). Extracting them to the top as named constants makes it easy to tune performance without digging through function logic.

### `parsePDF(pdfPath)` â€” New Inline PDF Parser

> **Why a new parser?** In Day18, `3_pdfParser.js` existed but was not used in the indexing pipeline because Gemini handled PDF reading directly. In Day19, the vector store needs to read the PDF independently, so a lightweight inline parser was added directly inside `6_vectorStore.js`. It does not import from `3_pdfParser.js` because the return format is different â€” `3_pdfParser.js` returns an array of movie blocks, while this parser returns the complete raw text as a single string.

This function:

1. Reads the PDF file from disk as a binary buffer using `fs.readFileSync()`
2. Parses the buffer using `pdf-parse` to extract all text from all pages
3. Returns the complete raw text as a single string

### `chunkText(rawText)` â€” Splitting Text into Chunks

This is a **new function** that did not exist in Day18. Its job is to take the full raw text from the PDF and split it into manageable, meaningful chunks.

How it works:

1. Splits the raw text by a pattern of 5 or more dashes on their own line (`/\n-{5,}\n/`) â€” this is the separator between individual movie entries in the PDF
2. For each resulting text block, trims whitespace
3. Filters out any blocks that are empty or shorter than 20 characters (to skip noise like stray separators or page breaks)
4. Returns an array of clean text chunks

Each chunk roughly corresponds to one movie's complete text entry from the PDF â€” but crucially, it is the **raw, unprocessed text** rather than a structured entity.

### `embedWithRetry(text, maxRetries)` â€” Embedding with Built-in Retry

> **Why this new function?** In Day18, the `embedTexts()` function was called without any retry mechanism. If the API call failed (due to rate limiting, network issues, or server errors), the entire batch was lost silently. In Day19, each individual chunk gets its own retry logic, ensuring maximum resilience.

This function wraps the `embedText()` call with retry logic:

1. Attempts to generate an embedding for the given text
2. If it fails:
   - **429 Error (Rate Limit)** â€” Waits longer: 20s, 40s, 60s (attempt Ã— 20 seconds)
   - **Any other error** â€” Waits shorter: 5s, 10s, 15s (attempt Ã— 5 seconds)
3. After all 3 attempts fail, returns `null` instead of throwing â€” this allows the pipeline to continue and track how many chunks failed

### `buildVectorStore(pdfPath)` â€” Main Function (Redesigned)

> **Signature change:** Previously `buildVectorStore(entities)`, now `buildVectorStore(pdfPath)`. This is the most visible indicator that the vector store no longer depends on entity extraction.

This function orchestrates the complete vector store building process. It works in 4 steps:

#### Step 1 â€” Parse the PDF

`parsePDF(pdfPath)` is called to extract the complete raw text from the PDF file. This happens locally on the machine using `pdf-parse` â€” it does **not** use Gemini for this step (unlike entity extraction which uploads the PDF to Gemini).

#### Step 2 â€” Chunk the text

`chunkText(rawText)` is called to split the raw text into individual chunks. The function also validates that at least some chunks were created â€” if the chunk count is zero (indicating an issue with the PDF format), the function returns early with an error message.

#### Step 3 â€” Embed all chunks

This is where the bulk of the work happens. Chunks are embedded in rounds of `EMBED_CONCURRENCY` (5 at a time):

1. For each round, `Promise.all()` fires 5 concurrent `embedWithRetry()` calls
2. Each successful embedding produces a vector record with:
   - **`id`** â€” A sequential identifier like `"chunk-0"`, `"chunk-1"`, etc. (unlike Day18 which used movie titles as IDs)
   - **`values`** â€” The 3072-dimensional embedding vector
   - **`metadata`** â€” Contains only the raw text of the chunk. This is much simpler than Day18 which stored title, year, director, genres, themes, actors, and text as separate metadata fields. The simplification works because the raw text itself contains all that information â€” when a similarity search returns a matching chunk, the full text provides all the context needed
3. Failed embeddings (where `embedWithRetry` returned `null`) are counted but do not block the pipeline
4. Progress is logged every 10 rounds and at the final round
5. A `EMBED_DELAY_MS` (500ms) pause is added between rounds to respect API rate limits

#### Step 4 â€” Upsert to Pinecone

> **Why a separate upsert step?** In Day18, embedding and upserting happened together in the same loop â€” each batch of 50 was embedded and immediately upserted. In Day19, all embeddings are generated first, then all vectors are upserted in a separate step. This separation provides clearer progress tracking (you know exactly how many embeddings succeeded before starting the upsert) and allows for larger, more efficient upsert batches.

The generated vectors are sent to Pinecone in batches of `UPSERT_BATCH_SIZE` (100 vectors per batch):

1. Vectors are sliced into batches of 100
2. Each batch is upserted via `pineconeIndex.upsert(batch)`
3. Progress is logged for each batch

At the end, `pineconeIndex.describeIndexStats()` is called to print the total vector count and total time taken, confirming that all data has been stored successfully.

---

## Complete Pipeline Flow Diagram

```
1. User runs: node 7_runIndexing.js
                    |
                    v
2. pdfPath = './data/movies.pdf' is set
                    |
                    v
3. runIndexing(pdfPath) is called
                    |
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        |           |                                      |
        v           v                                      v
   â”Œâ”€ STEP 1 â”€â”  â”Œâ”€â”€ STEP 2 â”€â”€â”               â”Œâ”€â”€â”€ STEP 3 â”€â”€â”€â”
   | Extract   |  | Build      |               | Parse PDF    |
   | Entities  |  | Neo4j Graph|               | â†’ Chunk      |
   | (Gemini)  |  | (Neo4j)    |               | â†’ Embed      |
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               | â†’ Pinecone   |
        |              ^                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        |              |                              ^
        â””â”€â”€entitiesâ”€â”€>â”€â”˜                              |
                                                      |
                           pdfPath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”˜
                                                      |
                                                      v
                                             closeConnections()
```

> **Notice:** In Day18, Step 3 received `entities` from Step 1. In Day19, Step 3 receives `pdfPath` directly â€” making it completely independent of entity extraction.

### File Dependency Chain

```
2_config.js (Foundation â€” all connections)
     â†‘ import           â†‘ import             â†‘ import
     |                  |                    |
4_entityExtractor.js  5_graphBuilder.js  6_vectorStore.js
(uses: genai,         (uses: driver)     (uses: embedText,
 createPartFromUri)                       pineconeIndex,
                                          fs, pdf-parse)
     â†‘ import           â†‘ import             â†‘ import
     |                  |                    |
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        |
                7_runIndexing.js (Entry Point)
```

### Summary Table

| File                   | Purpose                                                | Input          | Output                       | Changed from Day18?     |
| ---------------------- | ------------------------------------------------------ | -------------- | ---------------------------- | ----------------------- |
| `2_config.js`          | Sets up all connections (Neo4j, Pinecone, Gemini)      | `.env` file    | Exported clients & functions | âŒ No                   |
| `3_pdfParser.js`       | Extracts text from PDF (not directly used in pipeline) | PDF path       | Text blocks array            | âŒ No                   |
| `4_entityExtractor.js` | PDF â†’ Gemini â†’ Structured JSON entities                | PDF path       | Array of entity objects      | âš¡ Model upgraded       |
| `5_graphBuilder.js`    | Entities â†’ Neo4j graph (nodes + relationships)         | Entities array | Graph database populated     | âŒ No                   |
| `6_vectorStore.js`     | PDF â†’ Parse â†’ Chunk â†’ Embed â†’ Pinecone                 | **PDF path**   | Vector database populated    | âœ… **Complete rewrite** |
| `7_runIndexing.js`     | Calls all files in the correct order                   | PDF path       | Complete indexed system      | âš¡ Step 3 call changed  |

### All Changes at a Glance

| Change                      | File                   | What Changed                                               | Why                                                                      |
| --------------------------- | ---------------------- | ---------------------------------------------------------- | ------------------------------------------------------------------------ |
| Model upgrade               | `4_entityExtractor.js` | `gemini-2.5-flash-lite` â†’ `gemini-2.5-flash`               | Better accuracy, more reliable JSON output                               |
| Step 3 input change         | `7_runIndexing.js`     | `buildVectorStore(entities)` â†’ `buildVectorStore(pdfPath)` | Vector store now processes PDF independently                             |
| Vector store rewrite        | `6_vectorStore.js`     | Entity-based â†’ Chunk-based embedding                       | Richer embeddings, no information loss, decoupled from entity extraction |
| New functions added         | `6_vectorStore.js`     | `parsePDF()`, `chunkText()`, `embedWithRetry()`            | PDF parsing, text chunking, and resilient embedding                      |
| Retry added                 | `6_vectorStore.js`     | No retry â†’ `embedWithRetry()` with 3 attempts              | Prevents silent data loss on API failures                                |
| Record structure simplified | `6_vectorStore.js`     | Rich metadata (title, year, etc.) â†’ Just raw text          | Raw text is self-contained, no structured fields needed                  |
| Embedding approach changed  | `6_vectorStore.js`     | `embedTexts()` batch â†’ `embedText()` single with retry     | Per-chunk retry ensures maximum resilience                               |

> **Note:** `3_pdfParser.js` still exists but remains unused in the pipeline. The vector store has its own inline `parsePDF()` function because it needs the raw text as a single string, whereas `3_pdfParser.js` returns an array of movie blocks.
